#!/usr/bin/env python
"""
Setup Script - POD Duplicate Detector
======================================
Script t·ª± ƒë·ªông c√†i ƒë·∫∑t v√† ki·ªÉm tra m√¥i tr∆∞·ªùng.

S·ª≠ d·ª•ng:
    python setup_check.py         # Ki·ªÉm tra m√¥i tr∆∞·ªùng
    python setup_check.py --test  # Ki·ªÉm tra + ch·∫°y test nh·ªè
"""

import subprocess
import sys
import os

def print_header(text):
    print("\n" + "="*60)
    print(f"  {text}")
    print("="*60)

def print_ok(text):
    print(f"  ‚úÖ {text}")

def print_warn(text):
    print(f"  ‚ö†Ô∏è  {text}")

def print_error(text):
    print(f"  ‚ùå {text}")

def check_python():
    """Ki·ªÉm tra Python version"""
    print_header("KI·ªÇM TRA PYTHON")
    version = sys.version_info
    print(f"  Python {version.major}.{version.minor}.{version.micro}")
    
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print_error("C·∫ßn Python 3.8 tr·ªü l√™n!")
        return False
    print_ok("Python version OK")
    return True

def check_packages():
    """Ki·ªÉm tra c√°c package c·∫ßn thi·∫øt"""
    print_header("KI·ªÇM TRA PACKAGES")
    
    required = [
        ("PIL", "Pillow"),
        ("imagehash", "imagehash"),
        ("cv2", "opencv-python"),
        ("numpy", "numpy"),
        ("torch", "torch"),
        ("open_clip", "open-clip-torch"),
        ("sklearn", "scikit-learn"),
        ("requests", "requests"),
    ]
    
    missing = []
    for module, package in required:
        try:
            __import__(module)
            print_ok(f"{package}")
        except ImportError:
            print_error(f"{package} - CH∆ØA C√ÄI")
            missing.append(package)
    
    return missing

def check_torch():
    """Ki·ªÉm tra PyTorch v√† CUDA"""
    print_header("KI·ªÇM TRA PYTORCH & CUDA")
    
    try:
        import torch
        print(f"  PyTorch version: {torch.__version__}")
        
        if torch.cuda.is_available():
            print_ok(f"CUDA available: {torch.cuda.get_device_name(0)}")
            print(f"      CUDA version: {torch.version.cuda}")
            print(f"      GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            return "cuda"
        else:
            print_warn("CUDA kh√¥ng kh·∫£ d·ª•ng - S·ª≠ d·ª•ng CPU mode")
            print("      (V·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng, ch·ªâ ch·∫≠m h∆°n)")
            return "cpu"
    except ImportError:
        print_error("PyTorch ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t!")
        return None

def check_clip():
    """Ki·ªÉm tra OpenCLIP"""
    print_header("KI·ªÇM TRA OPENCLIP MODEL")
    
    try:
        import open_clip
        import torch
        
        print("  ƒêang load model ViT-B-32...")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        model, _, preprocess = open_clip.create_model_and_transforms(
            'ViT-B-32', 
            pretrained='openai',
            device=device
        )
        print_ok(f"Model loaded successfully on {device.upper()}")
        
        # Cleanup
        del model
        if device == "cuda":
            torch.cuda.empty_cache()
        
        return True
    except Exception as e:
        print_error(f"Kh√¥ng load ƒë∆∞·ª£c model: {e}")
        return False

def run_quick_test():
    """Ch·∫°y test nhanh v·ªõi ·∫£nh m·∫´u"""
    print_header("CH·∫†Y TEST NHANH")
    
    try:
        from pod_duplicate_detector import PODDuplicateDetector, DuplicateConfig
        
        print("  Kh·ªüi t·∫°o detector...")
        detector = PODDuplicateDetector()
        print_ok("Detector kh·ªüi t·∫°o th√†nh c√¥ng!")
        
        # Test v·ªõi ·∫£nh gi·∫£
        print("  Test x·ª≠ l√Ω ·∫£nh...")
        from PIL import Image
        import numpy as np
        
        # T·∫°o ·∫£nh test
        img = Image.fromarray(np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8))
        
        # Test c√°c h√†m c∆° b·∫£n
        normalized = detector._normalize_image(img)
        print_ok("Normalize image OK")
        
        phash = detector._compute_phash(normalized)
        print_ok(f"pHash computed: {phash}")
        
        embedding = detector._compute_clip_embedding(normalized)
        print_ok(f"CLIP embedding shape: {embedding.shape}")
        
        print_ok("T·∫•t c·∫£ tests passed!")
        return True
        
    except Exception as e:
        print_error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("\n" + "üîß "*20)
    print("    POD DUPLICATE DETECTOR - SETUP CHECK")
    print("üîß "*20)
    
    # Check Python
    if not check_python():
        sys.exit(1)
    
    # Check packages
    missing = check_packages()
    
    if missing:
        print_header("C√ÄI ƒê·∫∂T PACKAGES THI·∫æU")
        print(f"  Ch·∫°y l·ªánh sau ƒë·ªÉ c√†i ƒë·∫∑t:")
        print(f"  pip install -r requirements.txt")
        print()
        print("  Ho·∫∑c n·∫øu c√≥ GPU NVIDIA:")
        print(f"  pip install -r requirements-cuda.txt")
        sys.exit(1)
    
    # Check PyTorch/CUDA
    device = check_torch()
    if not device:
        sys.exit(1)
    
    # Check CLIP
    clip_ok = check_clip()
    
    # Run test if requested
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        run_quick_test()
    
    # Summary
    print_header("T·ªîNG K·∫æT")
    print_ok("M√¥i tr∆∞·ªùng ƒë√£ s·∫µn s√†ng!")
    print()
    print(f"  Device: {device.upper()}")
    print(f"  CLIP:   {'OK' if clip_ok else 'FAILED'}")
    print()
    print("  ƒê·ªÉ ch·∫°y detector:")
    print("    python run_detector.py")
    print()
    print("  Ho·∫∑c qua command line:")
    print("    python pod_duplicate_detector.py -i input.json -o output.json")
    print()

if __name__ == "__main__":
    main()
