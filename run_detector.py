"""
POD Duplicate Detector - Script ch·∫°y nhanh
==========================================
File n√†y gi√∫p b·∫°n ch·∫°y nhanh detector m√† kh√¥ng c·∫ßn command line arguments.

S·ª≠ d·ª•ng:
1. Ch·ªânh s·ª≠a c√°c ƒë∆∞·ªùng d·∫´n INPUT_FILE v√† OUTPUT_FILE b√™n d∆∞·ªõi
2. Ch·∫°y: python run_detector.py
"""

from pod_duplicate_detector import PODDuplicateDetector, DuplicateConfig, process_json_file
import os

# =============================================================================
# C·∫§U H√åNH - CH·ªàNH S·ª¨A T·∫†I ƒê√ÇY
# =============================================================================

# ƒê∆∞·ªùng d·∫´n file ƒë·∫ßu v√†o
INPUT_FILE = r"D:\Zecom AutoAgents\VPTEEK Project\match_case\output(1).json"

# ƒê∆∞·ªùng d·∫´n file ƒë·∫ßu ra (ƒë√£ l·ªçc tr√πng)
OUTPUT_FILE = r"D:\Zecom AutoAgents\VPTEEK Project\match_case\output_deduplicated(1).json"

# ƒê∆∞·ªùng d·∫´n file ch·ª©a c√°c item b·ªã lo·∫°i b·ªè (optional, set None n·∫øu kh√¥ng c·∫ßn)
REMOVED_FILE = r"D:\Zecom AutoAgents\VPTEEK Project\match_case\output_removed(1).json"

# ƒê∆∞·ªùng d·∫´n file ch·ª©a chi ti·∫øt c√°c c·∫∑p tr√πng (optional, set None n·∫øu kh√¥ng c·∫ßn)
PAIRS_FILE = r"D:\Zecom AutoAgents\VPTEEK Project\match_case\output_duplicate_pairs(1).json"

# C·∫•u h√¨nh ng∆∞·ª°ng detect (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh)
CONFIG = DuplicateConfig(
    # B∆∞·ªõc 0: Chu·∫©n h√≥a
    target_size=512,  # Resize v·ªÅ c·∫°nh d√†i n√†y
    
    # B∆∞·ªõc 1: pHash thresholds (CH·ªà L√Ä PRE-FILTER)
    phash_exact_threshold=3,      # ‚â§ 3: g·∫ßn nh∆∞ gi·ªëng pixel
    phash_likely_threshold=10,    # 4-10: c√≥ kh·∫£ nƒÉng tr√πng
    
    # B∆∞·ªõc 2: CLIP thresholds (LOGIC M·ªöI)
    # Full image threshold cao ƒë·ªÉ tr√°nh false positive
    clip_full_threshold=0.86,         # Full >= 0.86: DUPLICATE ch·∫Øc ch·∫Øn
    clip_center_threshold=0.83,       # Center >= 0.83: c·∫ßn boost + ORB confirm
    clip_min_center_boost=0.04,       # Center ph·∫£i cao h∆°n full ‚â•4% m·ªõi ƒë∆∞·ª£c d√πng
    clip_suspect_threshold=0.75,      # V√πng nghi v·∫•n cho ORB
    
    # B∆∞·ªõc 3: ORB threshold (h·∫° xu·ªëng ƒë·ªÉ d·ªÖ confirm h∆°n)
    orb_match_ratio_threshold=0.15,   # >= 0.15: tr√πng (center boost cases c·∫ßn ORB confirm)
    
    # Center crop ƒë·ªÉ lo·∫°i b·ªè watermark g√≥c
    use_center_crop=True,             # B·∫≠t center crop
    center_crop_ratio=0.65,           # Crop 65% v√πng gi·ªØa (b·ªè 17.5% m·ªói c·∫°nh)
    
    # CLIP model (c√≥ th·ªÉ ƒë·ªïi sang model kh√°c n·∫øu c·∫ßn)
    clip_model_name="ViT-B-32",
    clip_pretrained="openai"
)

# =============================================================================
# CH·∫†Y DETECTOR
# =============================================================================

if __name__ == "__main__":
    print("="*60)
    print("üé® POD MOCKUP DUPLICATE DETECTOR")
    print("="*60)
    print(f"\nüìÅ Input:  {INPUT_FILE}")
    print(f"üìÅ Output: {OUTPUT_FILE}")
    if REMOVED_FILE:
        print(f"üìÅ Removed: {REMOVED_FILE}")
    if PAIRS_FILE:
        print(f"üìÅ Pairs:   {PAIRS_FILE}")
    print()
    
    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(INPUT_FILE):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file input: {INPUT_FILE}")
        exit(1)
    
    # Ch·∫°y detector
    deduplicated, removed, stats, duplicate_pairs = process_json_file(
        input_path=INPUT_FILE,
        output_path=OUTPUT_FILE,
        removed_path=REMOVED_FILE,
        pairs_path=PAIRS_FILE,
        config=CONFIG,
        verbose=True
    )
    
    print("üéâ HO√ÄN TH√ÄNH!")
    print(f"   ƒê√£ l·ªçc {stats['duplicates_removed']} ·∫£nh tr√πng")
    print(f"   T√¨m th·∫•y {stats['duplicate_pairs_count']} c·∫∑p tr√πng")
    print(f"   C√≤n l·∫°i {stats['output_count']} ·∫£nh unique")
